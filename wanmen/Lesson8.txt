第八次课：模型评估(连续与离散)
	1.线性回归――连续变量模型结果衡量(面试)：
		残差和:SSE = sum((yi-yi')^2) //回归模型不能解释的偏差
	    回归平方和:SSR = sum((yi'-yi.mean)^2) //回归模型能够解释的偏差
	  	总偏差(离差)平方和:SST = sum((yi-yi.mean)^2) //原始数据本身具有的偏差
	  	有(可用 y = a*x + b 来证明)：
	  		SSE + SSR = SST
	  	R^2 = SSR/SST 样本总偏差平方和中，被回归平方和解释的百分比
	  	*由上述定义可知:R^2的大小与总体是否呈线性关系无关,与总体的参数显著性无关
	2.假设检验：
	       H0:原假设(一般为大概率事件)
	       	  一般地，要根据实际情况确定H0，不能一味地死搬硬套
	  P-value:在原假设H0成立时，出现观测值X0及更极端情况的概率
	  		  即：P(X>X0)或P(X<X0)或P(|X|>X0)等
	  		  *P-value的定义与H1无关，与是否拒绝H0更无关
	  		α:显著性水平,表示H0成立的情况下拒绝H0的概率，即第一类错误(弃真),一般取为0.05
	  	  1-α:置信水平
	  	   H1:备择假设
	  	    β:H1成立的情况下接受H0的概率，又称第二类错误(存伪)
	  	power:power = 1 - β
	  	   X^:接受或拒绝原假设的阈值(人为设定，可调整)
		判断标准:
	          if P-value < sig:
	          	拒绝H0
	          else：
	          	不拒绝H0
	          //一般好像是根据0.05和概率分布反算出X^,再看观测值X与X^的关系~~~          
	3.二分类问题的检验(分类一般通过logistic回归模型,下面是用来检验模型好坏的):
		二分类问题:指分类结果只有两类的分类问题，一般有如下四种结果：
				   将正类预测为正类:TP(true positive)
				   将正类预测为负类:FN(false negative)
				   将负类预测为正类:FP(false positive)
				   将负类预测为负类:TN(true negative)
	    召回率:阳性样本中被判断为阳性的概率
	   	   	   R = TP/(TP + FN)
	    准确度:被判断为阳性的样本中阳性样本的比例
	   		   P = TP/(TP + FP)
	    评价值:用于综合评价假设检验的好坏,计算方法为:
	   		   2/F1 = 1/P + 1/R
	   	真阳性率:正类中被正确判断为正类的概率
	  		   	 TPR = R
	    伪阳性率:负类中被错误判断为正类的概率
	  		     FPR = FP/(FP+TN)	 
	    ROC曲线(Receiver Operating Curve)：
	  		给定一个阈值,即可得到一组(FPR,TPR).将不同阈值下的点连接起来即得到ROC
	  		特点：a.曲线单调增,曲线可以位于45°线的任意一侧,但不能穿过45°线
	  		      b.曲线离45°线越远,分类效果越好
	  		      c.离45°线(随机分类)越远的点分类效果越好
	  		      *可结合b、c来选择最佳模型与确定阈值
	  		   	  d.曲线下方的面积 = AUC
	  		说明：a.ROC曲线最早用于二战时期衡量雷达识别效果
	  		  	  b.ROC衡量将分类事件转化为可衡量的量化标准的有效性
		二分类问题的python实现:
		from sklearn.metrics import f1_score,accuracy_score
		from sklearn.metrics import precision_score,recall_score
		f_score = f1_score(y1,y2) //F值
		pre_score = precision_score(y1,y2) //准确率
		re_score = recall_score(y1,y2) //召回率
		acc_score = accuracy_score(y1,y2) //正确率(整体的正确率)
		fpr,tpr = roc_curve(y1,y2) //伪、真阳性率
		roc_auc = roc_auc_score(y1,y2) //计算AUC
	4.多分类模型的评价(仍任是离散的):
		信息熵entropy = -Σ(P(yi)*ln(P(yi))) (i = 1 ... n)
		借鉴信息熵，引入cross_entropy:
			1)假设某分类问题有m个分类,一共n个样本,每个样本i的真实分类为yi
			2)利用模型对样本进行分类预测,结果为yi'
			3)对每个样本i,计算其真实分类yi在预测分类yi'中出现的概率,记作entropy_i
			4)计算cross_entropy = -1/n*Σ(ln(entropy_i)) (i = 1 ... n)
		*必须指出的是，选择不同的样本容量、不同的样本分布都会影响熵的基准值(即全部预测正确的情况)
		 因此该评价方法不能进行普遍意义上的比较,必须选择好具体样本之后才能进行模型的比较和评价
	5.imbalance(具体例子可参考课件或官方文档):
		指在二分类当中,正负样本的数量相差非常大,比如1:1000,此时正样本可能无法被识别
		解决方法:
			1.将负样本压缩――丢失重要信息,总体估计效果差
			2.增加正样本――过拟合
			3.先聚类,根据聚类结果进行子类挑选――过拟合
			4.合成数据,利用已有数据合理生成正样本(比如插值)――可能引入更多噪音,不适合高维数据
			5.集成算法,不改变样本
				 
		